---
title: '231B: Section 1'
author: "Natalia Garbiras-Díaz \\ https://github.com/nataliagarbirasdiaz/231b-Spring17"
date: "1/20/2017"
output: slidy_presentation
---

# Today 

* Overview of the course
* Getting started on R
* Functions and simulations

# Overview of the course

* My OHs are going to be Monday 4-6pm at Barrows 715.  
* I will draw a lot on the (great) material produced by Guadalupe Tuñón for previous years.

**Two goals:**

- Illustrating and understanding the concepts covered in lecture
- Going from learning R to programming in R

[Six steps to a better relationship with your future self.](http://polmeth.wustl.edu/methodologist/tpm_v18_n2.pdf)

Sections are *hands-on*: you will be expected to code on your own computers and to collaborate with your colleagues. For some sections, we will be using codeshare: https://codeshare.io/2pqoZ4

# We will be writing simulations and functions at least 80% of our time 

Here are some useful links to revisit the basics:

* Functions: [General thought on what makes a good function](http://nicercode.github.io/guides/functions/), [beginner](http://nicercode.github.io/intro/writing-functions.html), [intermediate/advanced](http://adv-r.had.co.nz/Functions.html). Shalizi on functions, [part 1](http://www.stat.cmu.edu/~cshalizi/statcomp/14/lectures/06/lecture-06.pdf) & [part 2](http://www.stat.cmu.edu/~cshalizi/statcomp/14/lectures/07/lecture-07.pdf).
* Simulations: [Repeating things](http://nicercode.github.io/guides/repeating-things/), [flow control and looping](http://www.stat.cmu.edu/~cshalizi/statcomp/14/lectures/03/lecture-03.pdf).

# Problem Sets

- Send a digital copy to nataliagarbirasdiaz+231b@berkeley.edu
- *Compiled versions* of your code. ".R" files will not be considered for grading. 
- Use [sweave, knitr](https://support.rstudio.com/hc/en-us/articles/200552056-Using-Sweave-and-knitr) or [R markdown](http://rmarkdown.rstudio.com/pdf_document_format.html)
- When debugging your code, [you might find Cosma Shalizi's advice helpful](http://www.stat.cmu.edu/~cshalizi/statcomp/14/lectures/13/lecture-13.pdf)
- Practice [defensive programming](http://adv-r.had.co.nz/Exceptions-Debugging.html)
- Problem sets will usually (but not always) be due in discussion section the Friday after it is handed out

# Why program? (Shalizi)

- **Independence**: Otherwise, you rely on someone else having given you exactly the right tool

- **Honesty**: Otherwise, you end up distorting your problem to match the tools you have

- **Clarity**: Making your method something a machine can do disciplines your thinking and makes it public

> Programs should be written for people to read, and only incidentally for
machines to execute (Abelson and Sussman)

# 1. Getting started on R (material from EGAP learning days)

## Why R? (extracted from Wickhan in Advanced R)

+ It's free, open source, and available on every major platform. As a result, if you do your analysis in R, anyone can easily replicate it.

+ A massive set of packages for statistical modelling, machine learning, visualisation, and importing and manipulating data. Whatever model or graphic you’re trying to do, chances are that someone has already tried to do it. At a minimum, you can learn from their efforts. (Plus, R can interact with other software or the web)

+ Researchers in statistics and machine learning will often publish an **R package** to accompany their articles. This means immediate access to the very latest statistical techniques and implementations.

+ It is easy to get help from experts on the R-help mailing list, stackoverflow, or subject-specific mailing lists 

+ Powerful tools for communicating your results. R packages make it easy to produce html or pdf reports, or create interactive websites.

+ A strong foundation in functional programming. The ideas of functional programming are well suited to solving many of the challenges of data analysis. R provides a powerful and flexible toolkit which allows you to write concise yet descriptive code.

Plus...

+ Widely and increasingly used among social scientists 

## What is R, how does it function?

R is an open-source (i.e., free access) programming tool. It is object-based: This means that everything in R is an object... even commands are also objects. For example:

```{r, echo=FALSE}
rm(list = ls())   
```

```{r,tidy=TRUE}
mean
```

In R, you can store objects using the `<-` operator. Make sure you give names to all objects:

```{r}
my.example <- 4 + 5
my.example
```

> "Names must be unique": everytime you give an `object` a `name`, it removes anything that already had that `name` from your environment!

Whenever you are not sure about how a command works, you can pull documentation using: `?`

```{r}
?mean
```

This tool is very helpful! Familiarize with it and feel comfortable using it... 

## Key commands: 

### Setting up your R session 

+ First, ask R which working directory you are currently working on. Then, set your local directory: note direction of strokes / (not \\). 

```{r}
getwd() # Let's see where we are currently working at... 
setwd("/Users/nataliagarbirasdiaz/Dropbox/Academic/UC_Berkeley/GSI/PS_231B/Section_slides/Section_1")   
```

+ Install any relevant packages (only has to be done once). 

```{r,eval=FALSE}
install.packages("Hmisc")  
```

+ *Load* any relevant packages.

```{r,message=FALSE,warning=FALSE}
library(Hmisc)
```

+ Clear R's memory     

```{r}
rm(list = ls())                                   
set.seed(20150420)        # OPT: Set a  seed to make replication possible. 
```

### Basics on R

Good, you're all set to start working on R. Let's explore some of the basic commands you will certainly be using. 

+ Creating and manipulating variables and vectors:

```{r}
a <- 5                 # "<-"  is the assignment command; it is used to define things. eg:
a

b <- 1:10              # ":"  is used to define a string of integers
b

v <- c(1,3,2,4,110,pi) # use c() to make a vector with anything in it (comes from combine)
v

# Extract elements of a vector:

b[1]                   # Returns position 1
b[6:5]                 # returns positions 6 and 5, in that order
b[-1]                  # Returns all but the first number  

# Returns all numbers indicated as "TRUE"
b[c(TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE)]  
                                                                          
# Assign new values to particular elements of a vector
b[5] <- 0
b
```

+ Manipulating Matrices:

```{r}
matrix(1:12, 3, 4)             # Make a 3X4 matrix with numbers 1:12
matrix(1:12, 4, 3)             # Make a 4X3 matrix with numbers 1:12
matrix(1:3, 4, 3)              # Make a 4X3 matrix with numbers 1:3, cycling; filling along by column
matrix(1:3, 4, 3, byrow=TRUE)  # Make a 4X3 matrix with numbers 1:3, cycling, filling  by row
```

+ Adding row names and column names to matrices

```{r}
M<-matrix(1:12, 3, 4)
rownames(M) = c("a","b","c")
colnames(M) = c("A","B","C", "Z")
M
```

+ Simple Functions on vectors (We'll get back to these functions)

```{r}
sum(b)                     # sum
mean(b)                    # mean
max(b)                     # max
min(b)                     # min
sd(b)                      # standard deviation
var(b)                     # variance
```

+ Simple transformations on vectors (or numbers, or matrices)

```{r}
b^2                        # Square the variable
matrix(1:3, 4, 3)^2        # Square the elements of a matrix 
b^.5                       # Square root of the variable
log(b)                     # log of variable
exp(b)                     # e to the b
```

+ Logical (asks to evaluate conditions)

```{r}
b==2                       # Is equal to
b<5                        # Less than
b>=5                       # Greater than or equal to 
b<=5 | b/4==2              # OR
b>2 & b<9                  # AND
is.na(b)                   # where is data missing
which(b<5)                 # gives indices of values meeting logical requirement
```

+ Distributions 

```{r}
rnorm(5)                      # Draws 5 obs. from standard normal distribution (mean 0, variance 1)
rbinom(5, 10, .4)             # Draws from a binomial distribution
runif(5)                      # Draws from a uniform distribution
```

+ Functions on PAIRS of variables

```{r}
x  = rnorm(100)               # Create variable "x" with 100 obs. from normal distribution
y  = x+rnorm(100)

y+x                            # Add variables together (or subtract, multiply etc)
y>x                            # Logical relation between two variables?
cor(x,y)                       # Correlation between variables
t.test(y~(x>.5))               # t-test of null that variables unrelated
lm(y~x)                        # OLS regression 
M<- lm(y~x)   
summary(M)                     # Summary of OLS regression
y%*%x                          # inner product of variables

# Make a dataframe and view it
d <- data.frame(x, y)
```

+ Loops: Loops repeat an operation/function over different values of *i*. See examples below:   

```{r}
x<-0                    
for(i in 1:10){         # repeat an expression for values of i in 1 to 10. 
  print(x<x+i)          # print allows you to see the results in the R console.  
   }

x=0
while(x <10){           # keep repeating an expression as long as some condition is satisfied
  print(x^2)
  x<-x+1
}

```

+ Apply and sapply: These two commands are very useful for efficient coding. They apply a function on an array or matrix. NOTE: You can always explore how these two commands work by typing `?apply` or `?sapply`.  

```{r}
sapply(1:4, function(j) j^2)   # faster way to do loops; this example runs function j^2 on 
                               # numbers j in 1:4
M<-matrix(rnorm(40), 4, 10)
apply(M, 1, mean)              # faster way to do lots of operations on a matrix: here take the mean 
                               # of every ROW (1)
apply(M, 2, sd)                # faster way to do lots of operations on a matrix: here take the sd  
                               # of every COLUMN (2)
```

#### Writing your own function: 

```{r}
h <- function(a, b=1) {        # Define any function by 1. assigning arguments (here a,b) and
                               # 2. giving any default values
     a^2 -b                    # (here b=1), and then giving the function
          }             
h(1)                           # illustration of function
h(1,2)                         # illustration of function

```

#### Parentheses

```{r}
# ( )   used for funtions, and for vectors: 
log(1)

# ( )   also used to keep things in blocks:
(1+2)/(2+1)
1+2/2+1

# [ ]   used to extract indices:
(10:12)[2]

# { } Used to keep blocks together, with final component returned:
x <- {
  a<-1
  b<-2
  a/b
}

x
```

### Ploting 

We will create two variables that are normally distributed and then will plot them (NOTE: I personally use [ggplot2](http://ggplot2.org) but basic R plots are great too! The DLab offers trannings exclusively on data visualization).

```{r}
y <- rnorm(10)                  # Generate y from a normal distribution 
x <- rnorm(10)                  # Generate y from a normal distribution 
```

Now let's plot both variables. 

```{r,warning=FALSE,message=FALSE}
par(mfrow = c(1,2))             # This lets you put a set of graphs on the same canvas -- here, 1*2
hist(y)                         # A histogram
boxplot(y~(x>0))                # Box plots
dev.off()                       # We tell R that we no longer want to plot in a 1 by 2 canvas. 
```

```{r}
plot(x,y)                       # xy plots  
abline(a=-1, b = 1, col="blue") # Add a sloped line
abline(v=mean(x), col="red")    # Add a vertical line
abline(lm(y~x))                 # Add a regression line
text(0, 0.2, "some text")       # Add text
title("An exercise")            # Add a title

# A "fancier" plot
x1 <- rnorm(100)
x2 <- rnorm(100) 
x3 <- rnorm(100)+x1+x2

plot(density(x1))           # We plot the distribution of x1. 

# How do we plot all three distributions?

plot(density(x1), main="Exercise")   #Notice we can add a title in the same plot command
lines(density(x2), col="slateblue")
lines(density(x3), lwd = 2)
lines(density(x1+x2), lty=2)

##Add a legend 
legend("topright", legend = c("x1","x2","x3","x1+x2"), 
       col = c("black", "slateblue", "black","black"),
       lty = c(1, 1, 1, 2), bg = "gray90")

```


2. A simulation in R: sample mean as an unbiased estimator of the population mean
======================================================================

First we will need to "create" a population, a *box of tickets*

```{r}
population <- c(4,5,7,12,7,8,9,-3,5,8,9,3,2,3,4,6,10,4,6,7,8,9,2)

N <- length(population) # number of observations in the population
N

pop_mean <- mean(population) # population mean
pop_mean 

pop_sd <- sd(population) # population standard deviation
pop_sd
```

----

We will draw several random samples of 8 observations ($m$) each *without* replacement 

```{r}
s1 <- sample(population, size=8, replace = FALSE)

s2 <- sample(population, size=8, replace = FALSE)

s3 <- sample(population, size=8, replace = FALSE)

s4 <- sample(population, size=8, replace = FALSE)

samples <- rbind(s1, s2, s3, s4)

samples
```

----

Remember the population mean: `r pop_mean`

And the means of the samples 

```{r} 
apply(samples, MARGIN=1, FUN=mean) 
```

By chance each given sample mean may be a little higher or lower than the population mean. 

How can we use R to show that the sample mean is an unbiased estimator of the population mean?

----

For this, we will write a *simulation*. We will repeat the sample process $10,000$ times.

```{r}

sample_mean <- NA

for (i in 1:10000){
  
  sample <- sample(population, size=8, replace = FALSE)
  sample_mean[i] <- mean(sample)
  
}
```

----

```{r}
par(mfrow=c(1,1))
plot(density(sample_mean), col="blue", lwd=3,
     main="Distribution of sample means")
abline(v=pop_mean, col="red", lwd=2)

average_sampling_distribution<- mean(sample_mean)
round(average_sampling_distribution,2)  
round(pop_mean, 2)

```

Let's now look at the distribution of the sample mean as $m$ gets closer to N.
======================================================================

So far, $m=8$. We now need a new simulation that adds a new step: we need to vary the size of *m*. (Remember our population size, *N*, is `r N`)

----

```{r, eval=FALSE}

rep <- 10000

# The first loop varies m
for (m in 9:20){

  sample_mean <- NA #creating an object to store the results of the second loop
  
  # The second loop goes through the 10,000 simulations
  for (i in 1:rep){
      
    #we first get a random sample of size m from the population
    sample <- sample(population, size=m, replace = FALSE)
    #and then calculate and store the sample mean
    sample_mean[i] <- mean(sample)
  }
  
  #finally, we plot the distribution of the 10,000 sample means for the relevant m
  lines(density(sample_mean), lwd=3,
        #note that this next line of code varies the color of the line according to m 
        #so that we can distinguish the different distributions
        col=paste0("grey",140-(7*m)))
}

```

What do we expect? Why?

----

```{r, echo=FALSE}

plot(density(sample_mean), col="blue", ylim=c(0,1.6),
     main="Distribution of sample means", lwd=3)
abline(v=pop_mean, col="red", lwd=3)

rep <- 10000

for (m in 9:20){
  sample_mean <- NA
  
  for (i in 1:rep){
    sample <- sample(population, size=m, replace = FALSE)
    sample_mean[i] <- mean(sample)
  }
  
  lines(density(sample_mean), lwd=3,
        col=paste0("grey",140-(7*m)))
}

```


3. Writing functions in R: the difference of two means
======================================================================

A function is composed by: i) body, ii) arguments, and iii) environment (usually Global unless otherwise specified)

```{r}

diff_means <- function(y, x){ 
  
  # Calculating difference in means
  mean1 <- mean(y[x==1], na.rm=T)
  mean0 <- mean(y[x==0], na.rm=T)
  diff <- mean1 - mean0
  
  # Calculating number of observations
  N <- length(na.omit(y))
  
  # Preparing output
  res <- c(mean1, mean0, diff, N)
  names(res) <- c("Mean 1", "Mean 0", "Difference", "N")
  
  return(c(res))
}
```

Now, let's explore the components of the function we just created: 

```{r}

body(diff_means)
formals(diff_means)
environment(diff_means)

```

----

To try our function, we will use the small dataset in Gerber & Green (2012)

```{r}
gg_data <- as.data.frame(cbind(c(10,15,20,20,10,15,15), 
                               c(15,15,30,15,20,15,30)))
names(gg_data) <- c("Y_i0", "Y_i1")
save(gg_data, file="gg_data.Rda")
```

(`"gg_data.Rda"` uploaded on bcourses and in the GitHub repository)

----

We will need to "create" a treatment vector...

```{r}
# let's fix m=3 (units in the treatment group)
treat <- c(1, 1, 1, 0, 0, 0, 0)
gg_data$treat <- sample(treat, 7, replace=F)
gg_data$treat
```

...and a column with the "observed" outcomes
```{r}
gg_data$observed <- ifelse(gg_data$treat==1, gg_data$Y_i1, gg_data$Y_i0)
```

----

Let's see how the complete data set looks now:

```{r}
head(gg_data)
```
----
```{r}
# mean of the treatment group
mean(gg_data$observed[gg_data$treat==1])
# mean of the control group
mean(gg_data$observed[gg_data$treat==0])

# difference of means
mean(gg_data$observed[gg_data$treat==1]) - mean(gg_data$observed[gg_data$treat==0])
  
# with our function
diff_means(gg_data$observed, gg_data$treat)

```

----

How can we get a distribution of the difference of means?
==============================================

Working in groups, we will combine 2 and 3 to write a simulation that generates the distribution of the difference in means.

Let's think about the steps first. 

---

For each simulation, 

> - First: We will need to "create" a random treatment vector and generate the column with the associated observed outcomes.

> - Second: We will have to calculate the difference between the treatment and control means (by hand or using our new function).

---

```{r}

# 1.
gg_data$treat <- sample(treat, 7, replace=F)
gg_data$observed <- ifelse(gg_data$treat==1, gg_data$Y_i1, gg_data$Y_i0)

# 2.
diff_means(gg_data$observed, gg_data$treat)
# we should store this! so,
dm <- diff_means(gg_data$observed, gg_data$treat)
dm
# but we only want the third element!
dm <- diff_means(gg_data$observed, gg_data$treat)[3]
dm

```

----

Now let's put this in a loop that allows us to repeat the process $10,000$ times (and saves the dom for each)...

```{r}

dm <- NA #creating a placeholder to store all our doms...

for (i in 1:10000){
    
    # 1.
    gg_data$treat <- sample(treat, 7, replace=F)
    gg_data$observed <- ifelse(gg_data$treat==1, gg_data$Y_i1, gg_data$Y_i0)
    
    # 2.
    dm[i] <- diff_means(gg_data$observed, gg_data$treat)[3]

    }

```

----

Finally, let's plot the distribution

```{r}
hist(dm, col="blue", main="Histogram of Difference of Means \n for GGdata")

```

# Problem set 1

- Simulation to show the difference of two means is unbiased
- Distribution of the difference of means as $m$ changes
- Extend the difference of means function to calculate the SE of the difference (we will cover SEs in lecture next week)
- Replicate figures and tables in Dunning and Harrison (2010) -- you will need your new function for this!

